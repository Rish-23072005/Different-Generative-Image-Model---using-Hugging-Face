# -*- coding: utf-8 -*-
"""Task-2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FHK6gQUGnThgaqUDP2u7p5HWfxBsN3G4
"""

# Install dependencies
!pip install diffusers transformers accelerate torch --quiet

#importing libraries
from diffusers import StableDiffusionPipeline, DiffusionPipeline
import torch
import matplotlib.pyplot as plt

# Set device
device = "cuda" if torch.cuda.is_available() else "cpu"

# Define prompt
prompt = "A futuristic cityscape at sunset, highly detailed, digital art"

# Load models
models = {
    "Stable Diffusion 1.5": "runwayml/stable-diffusion-v1-5",
    "Stable Diffusion XL": "stabilityai/stable-diffusion-xl-base-1.0",
    "Kandinsky 2.2": "kandinsky-community/kandinsky-2-2-decoder",
   #using 3 models

}

import time

images = {}
inference_times = {} # Initialize the dictionary to store inference times

for name, model_id in models.items():
    print(f"Generating with {name}...")
    if "kandinsky" in model_id:
        pipe = DiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)
    else:
        pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)
    pipe = pipe.to(device)

    # Measure inference time
    start_time = time.time()
    image = pipe(prompt).images[0]
    end_time = time.time()
    inference_time = end_time - start_time

    images[name] = image
    inference_times[name] = inference_time

# Plot results
plt.figure(figsize=(15, 5))
for i, (name, img) in enumerate(images.items()):
    plt.subplot(1, len(images), i+1)
    plt.imshow(img)
    plt.title(name)
    plt.axis("off")
plt.show()

